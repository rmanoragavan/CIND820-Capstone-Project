{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "!pip install imblearn\n",
    "!pip install delayed\n",
    "\n",
    "!pip install pydotplus\n",
    "import pydotplus\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import LeavePOut\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#Importing all the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVIDdf = pd.read_csv('COVID19 cases.csv')\n",
    "\n",
    "#Creating data frame for first dataset\n",
    "#Importing and reading CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPdf = pd.read_csv('neighbourhood-profiles-2016-csv.csv', index_col= \"_id\")\n",
    "\n",
    "#Creating data frame for second dataset\n",
    "#Importing and reading CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVIDdf.info()\n",
    "\n",
    "#Collecting information on dataset, columns, and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVIDdf = COVIDdf.drop([\"_id\",\"Assigned_ID\", \"Outbreak Associated\", \"FSA\", \"Source of Infection\", \"Classification\",\n",
    "                        \"Episode Date\",\"Currently Hospitalized\",\"Currently in ICU\",\"Currently Intubated\", \"Ever Hospitalized\", \n",
    "                        \"Reported Date\", \"Ever in ICU\",\"Ever Intubated\"], axis =1)\n",
    "\n",
    "#Cleaning the dataset\n",
    "#Removing unnecessary columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(COVIDdf.isnull().sum())\n",
    "\n",
    "#Checking dataset for any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVIDdf = COVIDdf.dropna()\n",
    "COVIDdf.count()\n",
    "\n",
    "#Dropping null values to clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(COVIDdf[\"Neighbourhood Name\"].value_counts())\n",
    "COVIDdf[\"Neighbourhood Name\"].value_counts().plot(kind = 'barh')\n",
    "\n",
    "#Finding value count of each neighbourhood\n",
    "#Plotting neighbourhood value count as a graph \n",
    "#Plotting to see COVID contraction density within each neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(COVIDdf[\"Age Group\"].value_counts())\n",
    "COVIDdf[\"Age Group\"].value_counts().plot(kind = 'barh')\n",
    "\n",
    "#Finding value count of each age group\n",
    "#Plotting as bar graph\n",
    "#Plotting to see age distrubution among COVID cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(COVIDdf[\"Client Gender\"].value_counts())\n",
    "COVIDdf[\"Client Gender\"].value_counts().plot(kind = 'barh')\n",
    "\n",
    "#Finding value count of each gender group\n",
    "#Plotting as bar graph\n",
    "#Plotting to find gender breakdown among COVID cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(COVIDdf[\"Outcome\"].value_counts())\n",
    "COVIDdf[\"Outcome\"].value_counts().plot(kind = 'barh')\n",
    "\n",
    "#Finding value count of each outcome group\n",
    "#Plotting as bar graph\n",
    "#Plotting to find outcome breakdown among COVID contracted cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agesexTable = COVIDdf.groupby([\"Age Group\"])[\"Client Gender\"].value_counts()\n",
    "agesexTable\n",
    "\n",
    "#Finding the gender group breakdown within each age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPagesexTable = COVIDdf.groupby([\"Neighbourhood Name\", \"Age Group\"])[\"Client Gender\"].value_counts()\n",
    "print(NPagesexTable)\n",
    "\n",
    "#Finding the age and gender group breakdown within each neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutcomeTable = COVIDdf.groupby(['Outcome', 'Age Group'])(['Client Gender']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPdf.reset_index(drop=True, inplace=True)\n",
    "NPdf.set_index(\"Category\", inplace=True)\n",
    "NPdf.head()\n",
    "\n",
    "#Cleaning the dataset\n",
    "#Resetting index to narrow down unwanted columns + rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPdf = NPdf.drop(['Aboriginal peoples','Education', 'Families, households and marital status','Housing','Immigration and citizenship',\n",
    "                  'Journey to work', 'Labour','Language', 'Language of work','Mobility', 'Neighbourhood Information', 'Population',\n",
    "                  'Visible minority'])\n",
    "\n",
    "#Dropping all the unwanted columns in the NPdf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPdf.reset_index(drop=True, inplace=True)\n",
    "NPdf.set_index(\"Topic\", inplace=True)\n",
    "\n",
    "#Resetting the index as \"Topic\" to further clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPdf = NPdf.drop(['Income of individuals in 2015', 'Income of economic families in 2015', 'Income sources', 'Income taxes', \n",
    "                  'Low income in 2015'])\n",
    "\n",
    "#Data cleaning\n",
    "#Dropping more unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPdf.reset_index(drop=True, inplace=True)\n",
    "NPdf = NPdf.drop([\"Data Source\"], axis=1)\n",
    "NPdf = NPdf.drop_duplicates(subset = \"Characteristic\", keep = \"first\")\n",
    "\n",
    "#Data cleaning\n",
    "#Resetting the index \n",
    "#Removing duplicate values under \"Characteristic\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPdf.set_index(\"Characteristic\", inplace=True)\n",
    "\n",
    "#Data cleaning\n",
    "#Setting index column as \"Characteristic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPdf = NPdf.dropna()\n",
    "\n",
    "#Dropping all null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPdf = NPdf.drop(['Total - Income statistics in 2015 for private households by household size - 100% data', \n",
    "                  '    Total - Income statistics in 2015 for one-person private households - 100% data'])\n",
    "\n",
    "NPdf = NPdf.drop(['    Total - Income statistics in 2015 for two-or-more-person private households - 100% data', \n",
    "                  'Total - Income statistics in 2015for private households by household size - 25% sampledata'])\n",
    "\n",
    "NPdf = NPdf.drop(['  Average after-tax income of households in 2015 ($)',\n",
    "                  '    Total - Income statistics in 2015 for one-person private households - 25% sample data'])\n",
    "\n",
    "NPdf= NPdf.drop(['Total - Household total income groups in 2015 for private households - 100% data',\n",
    "                 'Total - Household after-tax income groups in 2015 for private households - 100% data', \n",
    "                 '    Total - Income statistics in 2015 for two-or-more-person private households - 25% sample data'])\n",
    "\n",
    "#Dropping further columns to filter out specific income related data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPdf = NPdf.drop_duplicates(keep = \"first\")\n",
    "\n",
    "#Dropping any duplicates within dataset\n",
    "#Choosing the first value to stay within dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPdf= NPdf.T\n",
    "\n",
    "#Transposing dataframe to be able to get the characterisitcs as columns, with neighbourhoods as rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPdf = NPdf.drop(['    $150,000 to $199,999', '    $100,000 to $124,999', '    $125,000 to $149,999', '    $200,000 and over'], axis = 1)\n",
    "\n",
    "#Dropping unnecessary columns to filter out specific income related data values for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in NPdf.columns:\n",
    "    print(col)\n",
    "    \n",
    "#Printing all the income related and ethnicity related columns within dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['  Under $5,000', '  $5,000 to $9,999', '  $10,000 to $14,999', '  $15,000 to $19,999', '  $20,000 to $24,999', \n",
    "                                  '  $25,000 to $29,999', '  $30,000 to $34,999', '  $35,000 to $39,999','  $40,000 to $44,999','  $45,000 to $49,999',\n",
    "                                  '  $50,000 to $59,999', '  $60,000 to $69,999', '  $70,000 to $79,999', '  $80,000 to $89,999', '  $90,000 to $99,999',\n",
    "                                  '  $100,000 and over']\n",
    "IncomeProfile = NPdf.loc[:,data]\n",
    "\n",
    "#Creating new dataframe specifically for Income Profile from Neighbourhood Profile dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IncomeProfile.dtypes\n",
    "\n",
    "#Returning data types of columns in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IncomeProfile = IncomeProfile.replace(',', '', regex=True)\n",
    "\n",
    "#Fixing cell values of IncomeProfile\n",
    "#Removing the ',' in cell values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = IncomeProfile.select_dtypes(object).columns\n",
    "IncomeProfile[c] = IncomeProfile[c].apply(pd.to_numeric,errors='coerce')\n",
    "\n",
    "#Converting cell values from object into integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IncomeProfile.dtypes\n",
    "\n",
    "#Checking to see values converted from object into integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IncomeProfile = IncomeProfile.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AvgIncomeProfile = IncomeProfile\n",
    "\n",
    "#Creating new dataframe\n",
    "#Copying IncomeProfile df into AvgIncomeProfile df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AvgIncomeProfile.index\n",
    "\n",
    "#Checking index column in new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AvgIncomeProfile = AvgIncomeProfile.drop(['City of Toronto'], axis=1)\n",
    "\n",
    "#Dropping unnecessary column for this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AvgIncomeProfile['Average'] = 0\n",
    "\n",
    "#Creating new column 'Average' for AvgIncomeProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AvgIncomeProfile.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AvgIncomeProfile.loc['  Under $5,000']['Average'] = 2500\n",
    "AvgIncomeProfile.loc['  $5,000 to $9,999']['Average'] = 7500\n",
    "AvgIncomeProfile.loc['  $10,000 to $14,999']['Average'] = 12500\n",
    "AvgIncomeProfile.loc['  $15,000 to $19,999']['Average'] = 17500\n",
    "AvgIncomeProfile.loc['  $20,000 to $24,999']['Average'] = 22500\n",
    "AvgIncomeProfile.loc['  $25,000 to $29,999']['Average'] = 27500\n",
    "AvgIncomeProfile.loc['  $30,000 to $34,999']['Average'] = 32500\n",
    "AvgIncomeProfile.loc['  $35,000 to $39,999']['Average'] = 37500\n",
    "AvgIncomeProfile.loc['  $40,000 to $44,999']['Average'] = 42500\n",
    "AvgIncomeProfile.loc['  $45,000 to $49,999']['Average'] = 47500\n",
    "AvgIncomeProfile.loc['  $50,000 to $59,999']['Average'] = 55000\n",
    "AvgIncomeProfile.loc['  $60,000 to $69,999']['Average'] = 65000\n",
    "AvgIncomeProfile.loc['  $70,000 to $79,999']['Average'] = 75000\n",
    "AvgIncomeProfile.loc['  $80,000 to $89,999']['Average'] = 85000\n",
    "AvgIncomeProfile.loc['  $90,000 to $99,999']['Average'] = 95000\n",
    "AvgIncomeProfile.loc['  $100,000 and over']['Average'] = 100000\n",
    "\n",
    "#Adding values into 'Average' column with median value of each Income range (index column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in AvgIncomeProfile.columns:\n",
    "    if col != 'Average':\n",
    "        AvgIncomeProfile[col] *= AvgIncomeProfile['Average']\n",
    "\n",
    "#Creating 'for' loop to calculate product of 'Average' column with each cell value\n",
    "#Cell value represents number of people that have x income range within each neighbourhood\n",
    "#First step to finding average income of each neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AvgIncomeProfile\n",
    "\n",
    "#Printing dataframe to see if loop produced required results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalIncomeProfile = pd.DataFrame(index = ['FinalAvg'], columns = IncomeProfile.columns)\n",
    "FinalIncomeProfile = FinalIncomeProfile.drop(['City of Toronto'], axis = 1)\n",
    "\n",
    "#Creating new dataframe to calculate average income of each neighbourhood\n",
    "#Using columns from IncomeProfile DF to copy into new dataframe\n",
    "#Dropping columm \"City of Toronto\", as it is not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalIncomeProfile\n",
    "\n",
    "#Printing dataframe to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in FinalIncomeProfile.columns:\n",
    "    FinalIncomeProfile[col] = round((AvgIncomeProfile[col].sum()/IncomeProfile[col].sum()),2)\n",
    "\n",
    "#Creating for loop to calculate last step to finding average income for each neighbourhood\n",
    "#Weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalIncomeProfile\n",
    "\n",
    "#Printing dataframe with newly calculated averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Want to merge FinalAvg values from FinalIncomeProfile into COVIDdf for further analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neighbourhoodlist = FinalIncomeProfile.T\n",
    "\n",
    "#Creating new variable 'Neighbourhoodlist'\n",
    "#Transoposing FinalIncomeProfile in order to get neighbourhood names as rows, with FinalAvg as column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neighbourhoodlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neighbourhoodlist = Neighbourhoodlist.to_dict()\n",
    "\n",
    "#Changing Neighbourhoodlist from dataframe into dictionary\n",
    "#Making this change will make it possible to add FinalAvg onto COVIDdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neighbourhoodlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVIDdf['NeighbourhoodAvgIncome'] = 0\n",
    "\n",
    "#Creating new column in COVIDdf to add neighbourhood average income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVIDdf['NeighbourhoodAvgIncome'] = COVIDdf['Neighbourhood Name'].map(Neighbourhoodlist['FinalAvg'])\n",
    "\n",
    "#Using Neighbourhoodlist to average income, by matching with neighbourhood names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutcomeNames = COVIDdf[COVIDdf['Outcome'] == 'ACTIVE'].index\n",
    "\n",
    "COVIDdf.drop(OutcomeNames, inplace = True)\n",
    "COVIDdf\n",
    "\n",
    "#Data prep for analysis\n",
    "#Dropping 'ACTIVE' in COVIDdf.Outcomes because not needed for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutcomeRandomization = COVIDdf\n",
    "\n",
    "#Creating identical COVIDdf dataframe to be used for randomized dropping of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutcomeRandomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVIDdf = COVIDdf.loc[COVIDdf['Outcome'] == 'FATAL']\n",
    "COVIDdf\n",
    "\n",
    "#Choosing to only keep 'Outcome' values with only 'FATAL' in COVIDdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutcomeRandomization = OutcomeRandomization.loc[OutcomeRandomization['Outcome'] == 'RESOLVED']\n",
    "OutcomeRandomization\n",
    "\n",
    "#Choosing to only keep 'Outcome' values with only 'RESOLVED' in OutcomeRandomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "Nremove = 97587\n",
    "\n",
    "drop_indices = np.random.choice(OutcomeRandomization.index, Nremove, replace=False)\n",
    "OutcomeRandomization = OutcomeRandomization.drop(drop_indices)\n",
    "OutcomeRandomization\n",
    "\n",
    "#Need to randomly select to keep 2759/100346 rows in OutcomeRandomization\n",
    "#Need to have same number of 'RESOLVED' as 'FATAL' for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [COVIDdf, OutcomeRandomization]\n",
    "COVIDdf = pd.concat(frames)\n",
    "\n",
    "#Adding OutcomeRandomization into COVIDdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVIDdf['Outcome'] = COVIDdf['Outcome'].replace(['FATAL', 'RESOLVED'], [0,1])\n",
    "COVIDdf\n",
    "\n",
    "#Changing 'Outcome' values from 'FATAL','RESOLVED', into '0','1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVIDdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVIDdf = COVIDdf.fillna(0) \n",
    "\n",
    "#Filling NA values with value of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(COVIDdf['NeighbourhoodAvgIncome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVIDdf.describe()\n",
    "\n",
    "#Descriptive stats for COVIDdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVIDdf = pd.get_dummies(COVIDdf)\n",
    "\n",
    "#One-hot encoding the categorical variables (\"Age Group\" and \"Client Gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVIDdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVIDdf.groupby('Outcome').mean()\n",
    "\n",
    "#Breaking down and analysing dataset by 'Outcome'\n",
    "#Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "LogCOVIDdf = COVIDdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in COVIDdf.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogCOVIDdf = COVIDdf\n",
    "\n",
    "#Creating new dataframe for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = LogCOVIDdf.loc[:, LogCOVIDdf.columns != 'Outcome']\n",
    "y = LogCOVIDdf.loc[:, LogCOVIDdf.columns == 'Outcome']\n",
    "y = y.astype('int')\n",
    "\n",
    "os = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns\n",
    "\n",
    "\n",
    "os_data_X,os_data_y=os.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['Outcome'])\n",
    "\n",
    "print(\"Length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['Outcome']==0]))\n",
    "print(\"Number of subscription\",len(os_data_y[os_data_y['Outcome']==1]))\n",
    "print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['Outcome']==0])/len(os_data_X))\n",
    "print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['Outcome']==1])/len(os_data_X))\n",
    "\n",
    "#Implementing SMOTE\n",
    "#Creating perfectly balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cdf_final_vars = LogCOVIDdf.columns.values.tolist()\n",
    "y = ['Outcome']\n",
    "X =[i for i in Cdf_final_vars if i not in y ]\n",
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, 20)\n",
    "rfe = rfe.fit(os_data_X, os_data_y.values.ravel())\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "\n",
    "#RecursiveFeatureElimination\n",
    "#Help select best and worst features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Age Group_19 and younger', 'Age Group_20 to 29 Years', 'Age Group_30 to 39 Years', 'Age Group_40 to 49 Years', \n",
    "        'Age Group_60 to 69 Years', 'Age Group_70 to 79 Years', 'Age Group_80 to 89 Years', 'Age Group_90 and older',\n",
    "        'Neighbourhood Name_Birchcliffe-Cliffside', 'Neighbourhood Name_Casa Loma','Neighbourhood Name_Downsview-Roding-CFB',\n",
    "        'Neighbourhood Name_Englemount-Lawrence', 'Neighbourhood Name_Forest Hill North', 'Neighbourhood Name_Lawrence Park North',\n",
    "        'Neighbourhood Name_Maple Leaf', 'Neighbourhood Name_Morningside', 'Neighbourhood Name_Old East York', \n",
    "        'Neighbourhood Name_South Parkdale', 'Neighbourhood Name_Trinity-Bellwoods', 'Neighbourhood Name_Yorkdale-Glen Park']\n",
    "\n",
    "X=os_data_X[cols]\n",
    "y=os_data_y['Outcome']\n",
    "\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X)\n",
    "\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "\n",
    "#Selecting best features\n",
    "#Implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Age Group_19 and younger', 'Age Group_20 to 29 Years', 'Age Group_30 to 39 Years', 'Age Group_40 to 49 Years', \n",
    "        'Age Group_70 to 79 Years', 'Age Group_80 to 89 Years', 'Age Group_90 and older',\n",
    "        'Neighbourhood Name_Casa Loma','Neighbourhood Name_Downsview-Roding-CFB','Neighbourhood Name_Englemount-Lawrence',\n",
    "        'Neighbourhood Name_Forest Hill North','Neighbourhood Name_Trinity-Bellwoods', 'Neighbourhood Name_Yorkdale-Glen Park']\n",
    "\n",
    "X=os_data_X[cols]\n",
    "y=os_data_y['Outcome']\n",
    "\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X)\n",
    "\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "\n",
    "#Remove features with p-value higher than 0.05\n",
    "#Implementing model with fewer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "\n",
    "#Predicting the test set results and calculating the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "\n",
    "#result is telling us that we have 488+89 correct predictions and 61+522 incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Compute precision, recall, F-measure and support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()\n",
    "\n",
    "#ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RfCOVIDdf = COVIDdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(RfCOVIDdf['Outcome'])\n",
    "RfCOVIDdf = RfCOVIDdf.drop('Outcome', axis =1)\n",
    "RfCOVIDdf_list = list(RfCOVIDdf.columns)\n",
    "RfCOVIDdf = np.array(RfCOVIDdf)\n",
    "\n",
    "#Creating labels as values to be predicted for model\n",
    "#Removing labels from COVIDdf\n",
    "#Storing COVIDdf names for later use\n",
    "#Converting COVIDdf dataframe into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_COVIDdf, test_COVIDdf, train_labels, test_labels = train_test_split(RfCOVIDdf, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "# Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training COVIDdf Shape:', train_COVIDdf.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing COVIDdfs Shape:', test_COVIDdf.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 1, random_state = 1)\n",
    "rf.fit(train_COVIDdf, train_labels);\n",
    "\n",
    "# Import the model we are using\n",
    "# Instantiate model with 1 decision trees\n",
    "# Train the model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf.predict(test_COVIDdf)\n",
    "errors = abs(predictions - test_labels)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "# Calculate the absolute errors\n",
    "# Print out the mean absolute error (mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 10, random_state = 10)\n",
    "rf.fit(train_COVIDdf, train_labels);\n",
    "\n",
    "\n",
    "predictions = rf.predict(test_COVIDdf)\n",
    "errors = abs(predictions - test_labels)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "Accuracycount = 0\n",
    "\n",
    "for i in range(0, len(predictions)):\n",
    "    if predictions[i] == test_labels[i]:\n",
    "          Accuracycount +=1\n",
    "\n",
    "Accuracy = 100* Accuracycount/ len(predictions)\n",
    "Accuracy\n",
    "\n",
    "# Instantiate model with 10 decision trees\n",
    "# Train the model on training data\n",
    "# Use the forest's predict method on the test data\n",
    "# Calculate the absolute errors\n",
    "# Print out the mean absolute error (mae)\n",
    "# Print out accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 15, random_state = 1)\n",
    "rf.fit(train_COVIDdf, train_labels);\n",
    "\n",
    "predictions = rf.predict(test_COVIDdf)\n",
    "errors = abs(predictions - test_labels)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "Accuracycount = 0\n",
    "\n",
    "for i in range(0, len(predictions)):\n",
    "    if predictions[i] == test_labels[i]:\n",
    "          Accuracycount +=1\n",
    "\n",
    "Accuracy = 100* Accuracycount/ len(predictions)\n",
    "Accuracy\n",
    "\n",
    "# Instantiate model with 15 decision trees\n",
    "# Train the model on training data\n",
    "# Use the forest's predict method on the test data\n",
    "# Calculate the absolute errors\n",
    "# Print out the mean absolute error (mae)\n",
    "# Print out accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 1)\n",
    "rf.fit(train_COVIDdf, train_labels);\n",
    "\n",
    "predictions = rf.predict(test_COVIDdf)\n",
    "errors = abs(predictions - test_labels)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "Accuracycount = 0\n",
    "\n",
    "for i in range(0, len(predictions)):\n",
    "    if predictions[i] == test_labels[i]:\n",
    "          Accuracycount +=1\n",
    "\n",
    "Accuracy = 100* Accuracycount/ len(predictions)\n",
    "Accuracy\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "# Train the model on training data\n",
    "# Use the forest's predict method on the test data\n",
    "# Calculate the absolute errors\n",
    "# Print out the mean absolute error (mae)\n",
    "# Print out accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 150, random_state = 10)\n",
    "rf.fit(train_COVIDdf, train_labels);\n",
    "\n",
    "predictions = rf.predict(test_COVIDdf)\n",
    "errors = abs(predictions - test_labels)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "Accuracycount = 0\n",
    "\n",
    "for i in range(0, len(predictions)):\n",
    "    if predictions[i] == test_labels[i]:\n",
    "          Accuracycount +=1\n",
    "\n",
    "Accuracy = 100* Accuracycount/ len(predictions)\n",
    "Accuracy\n",
    "\n",
    "# Instantiate model with 150 decision trees\n",
    "# Train the model on training data\n",
    "# Use the forest's predict method on the test data\n",
    "# Calculate the absolute errors\n",
    "# Print out the mean absolute error (mae)\n",
    "# Print out accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 1)\n",
    "rf.fit(train_COVIDdf, train_labels);\n",
    "\n",
    "predictions = rf.predict(test_COVIDdf)\n",
    "errors = abs(predictions - test_labels)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "Accuracycount = 0\n",
    "\n",
    "for i in range(0, len(predictions)):\n",
    "    if predictions[i] == test_labels[i]:\n",
    "          Accuracycount +=1\n",
    "\n",
    "Accuracy = 100* Accuracycount/ len(predictions)\n",
    "Accuracy\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "# Train the model on training data\n",
    "# Use the forest's predict method on the test data\n",
    "# Calculate the absolute errors\n",
    "# Print out the mean absolute error (mae)\n",
    "# Print out accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 1, random_state = 1)\n",
    "rf.fit(train_COVIDdf, train_labels);\n",
    "\n",
    "\n",
    "predictions = rf.predict(test_COVIDdf)\n",
    "errors = abs(predictions - test_labels)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "Accuracycount = 0\n",
    "\n",
    "for i in range(0, len(predictions)):\n",
    "    if predictions[i] == test_labels[i]:\n",
    "          Accuracycount +=1\n",
    "\n",
    "Accuracy = 100* Accuracycount/ len(predictions)\n",
    "Accuracy\n",
    "\n",
    "# Instantiate model with 1 decision trees\n",
    "# Train the model on training data\n",
    "# Use the forest's predict method on the test data\n",
    "# Calculate the absolute errors\n",
    "# Print out the mean absolute error (mae)\n",
    "# Print out accuracy\n",
    "# This model has highest accuracy out of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = rf.estimators_[0]\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = RfCOVIDdf_list, rounded = True, precision = 1)\n",
    "(graph, ) = pydotplus.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('tree.png')\n",
    "\n",
    "# Import tools needed for visualization\n",
    "# Pull out one tree from the forest\n",
    "# Export the image to a dot file\n",
    "# Use dot file to create a graph\n",
    "# Write graph to a png file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "RfCOVIDdf_importances = [(RfCOVIDdf, round(importance, 2)) for RfCOVIDdf, importance in zip(RfCOVIDdf_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "RfCOVIDdf_importances = sorted(RfCOVIDdf_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in RfCOVIDdf_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New random forest with only the two most important variables\n",
    "rf_most_important = RandomForestRegressor(n_estimators= 1, random_state=1)\n",
    "# Extract the two most important features\n",
    "important_indices = [RfCOVIDdf_list.index('Age Group_90 and older'), RfCOVIDdf_list.index('Age Group_80 to 89 Years')]\n",
    "train_important = train_COVIDdf[:, important_indices]\n",
    "test_important = test_COVIDdf[:, important_indices]\n",
    "# Train the random forest\n",
    "rf_most_important.fit(train_important, train_labels)\n",
    "# Make predictions and determine the error\n",
    "predictions = rf_most_important.predict(test_important)\n",
    "errors = abs(predictions - test_labels)\n",
    "# Display the performance metrics\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "mape = np.mean(100 * (errors / test_labels))\n",
    "\n",
    "Accuracycount = 0\n",
    "\n",
    "for i in range(0, len(predictions)):\n",
    "    if predictions[i] == test_labels[i]:\n",
    "          Accuracycount +=1\n",
    "\n",
    "Accuracy = 100* Accuracycount/ len(predictions)\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-FOLD CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfCOVIDdf = COVIDdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = kfCOVIDdf.drop('Outcome', axis =1).values\n",
    "Y = kfCOVIDdf['Outcome'].values\n",
    "\n",
    "#Creating X and Y values for K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=100, shuffle = True)\n",
    "model_kfold = LogisticRegression()\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) \n",
    "\n",
    "# evaluate a logistic regression model using repeated k-fold cross-validation, 10-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=9, random_state=100, shuffle = True)\n",
    "model_kfold = LogisticRegression()\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=8, random_state=100, shuffle = True)\n",
    "model_kfold = LogisticRegression()\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=7, random_state=100, shuffle = True)\n",
    "model_kfold = LogisticRegression()\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=6, random_state=100, shuffle = True)\n",
    "model_kfold = LogisticRegression()\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=5, random_state=100, shuffle = True)\n",
    "model_kfold = LogisticRegression()\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=4, random_state=100, shuffle = True)\n",
    "model_kfold = LogisticRegression()\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=3, random_state=100, shuffle = True)\n",
    "model_kfold = LogisticRegression()\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=2, random_state=100, shuffle = True)\n",
    "model_kfold = LogisticRegression()\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "from matplotlib import pyplot\n",
    "def evaluate_model(X, Y, repeats):\n",
    "\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    model = LogisticRegression()\n",
    "    scores = cross_val_score(model, X, Y, scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "repeats = range(1,16)\n",
    "results = list()\n",
    "\n",
    "for r in repeats:\n",
    "    scores = evaluate_model(X, Y, r)\n",
    "    print('>%d mean=%.4f se=%.3f' % (r, mean(scores), sem(scores)))\n",
    "    results.append(scores)\n",
    "# plot the results\n",
    "pyplot.boxplot(results, labels=[str(r) for r in repeats], showmeans=True)\n",
    "pyplot.show()\n",
    "\n",
    "#Created function to find mean, se for K-folds of 1-15\n",
    "#Created box-and-whisker plot for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
